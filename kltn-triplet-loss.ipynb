{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMAGE SIMILARITY USING TRIPLET LOSS","metadata":{"id":"LHmpjM9c6SVd"}},{"cell_type":"markdown","source":"## A - Set-up the working environment","metadata":{"id":"ieR_vfsy53vE"}},{"cell_type":"markdown","source":"### I - Import packages","metadata":{"id":"yrcc0rBR5_5E"}},{"cell_type":"code","source":"import os\nimport math\nimport random\nimport gc","metadata":{"id":"apLa5BOGa99M","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport PIL\nfrom matplotlib import image as mpimg\nimport tensorflow_datasets as tfds\nimport pathlib","metadata":{"id":"HTFkt4yNKk0p","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### II - Define global constants","metadata":{"id":"-G-Q3CGV6NOQ"}},{"cell_type":"code","source":"VAL_SIZE = 0.2\nRANDOM_STATE = 21\nBATCH_SIZE = 32\nEPOCHS = 1000\nIMAGE_SIZE_H = 64 #245(tll) 32(cf10)\nIMAGE_SIZE_W = 64 #200(tll) 32(cf10)","metadata":{"id":"NxLR5Hm0MHa9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CHECKPOINT_PATH = \"checkpoint/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## B -  Preprocess the data","metadata":{"id":"XkuSyyD95sVZ"}},{"cell_type":"markdown","source":"### I - Split the dataset into train, valid, and test set","metadata":{"id":"tBjMcNhW5zBC"}},{"cell_type":"code","source":"# /kaggle/input/totally-looks-like-dataset\ncache_dir = pathlib.Path(\"/kaggle/input/totally-looks-like-ds2/totally_looks_like_ds2\")\nprint(cache_dir)\nanchor_images_path = cache_dir / \"left/left\"\nsimilar_images_path = cache_dir / \"right/right\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count = len(list(anchor_images_path.glob('*.jpg')))\ndatasets = []\nlabels  = []\n\nfor i in range(image_count):\n    try:\n        anchor_image_path = list(anchor_images_path.glob(f'{i:05d}.jpg'))[0]\n        similar_image_path = list(similar_images_path.glob(f'{i:05d}.jpg'))[0]\n        \n#         anchor_image = np.asarray(PIL.Image.open(anchor_image_path)).astype('float16')\n#         similar_image = np.asarray(PIL.Image.open(similar_image_path)).astype('float16')\n        \n        labels.append(i)\n        datasets.append([anchor_image_path, similar_image_path])\n        \n    except Exception as e:\n        print(f\"{e}\")\n        \ndataset_images = np.array(datasets)\ndataset_labels = np.array(labels)\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 5870\nanchor_image = list(similar_images_path.glob(f'{i:05d}.jpg'))[0]\nplt.imshow(np.asarray(PIL.Image.open(anchor_image)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset_labels.shape)\nprint(dataset_images.shape)\nprint(type(dataset_images[0][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(\n    train_images, val_images, train_labels, val_labels\n) = train_test_split(\n    dataset_images, dataset_labels, test_size=VAL_SIZE, random_state=RANDOM_STATE\n)","metadata":{"id":"FYNGZKBtLZvf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %reset_selective -f  dataset_images\n# %reset_selective -f dataset_labels\ndel  dataset_images\ndel dataset_labels\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_images.reshape(-1)\nval_images = val_images.reshape(-1)\ntrain_labels = np.repeat(train_labels, 2)\nval_labels = np.repeat(val_labels, 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_images.shape)\nprint(train_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(val_images)","metadata":{"id":"FvZldXHiM62o","outputId":"94fbcc30-bc48-479a-f5b6-56c0acb405e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### II - Group images into triplets","metadata":{"id":"UNbDpTft6cv9"}},{"cell_type":"code","source":"class ImageTriplets(keras.utils.Sequence):\n    def __init__(self, images, labels, batch_size):\n        self._images = images\n        self._labels = labels\n        self._indices = np.arange(len(images))\n        self._idx_groups = self._group_indices_by_labels()\n        self._unique_labels = self._idx_groups.keys()\n        self._batch_size = batch_size\n        random.shuffle(self._indices)\n\n    def __len__(self):\n        return math.ceil(len(self._images) / self._batch_size)\n\n    def __getitem__(self, batch_idx):\n        \"\"\"\n        Return a batch of triplets containing an anchor image, a positive image, \n        and a negative image. Each triplet is uniquely identified by its anchor\n        image.\n        \"\"\"\n        start_idx = min(self._batch_size * batch_idx, len(self._indices) - self._batch_size)\n        end_idx = min(self._batch_size * (batch_idx + 1), len(self._indices))\n        anchor_image_indices = self._indices[start_idx:end_idx]\n        batch = np.stack(\n            [self._make_triplet(idx) for idx in anchor_image_indices]\n        )\n        return batch\n\n    def on_epoch_end(self):\n        np.random.shuffle(self._indices)\n    \n    def _group_indices_by_labels(self):\n        \"\"\"\n        Return a dict with label as key and a indices list of samples with the \n        corresponding label as value.\n        \"\"\"\n        idx_groups = {}\n\n        for label, idx in zip(self._labels.ravel(), self._indices):\n            if label not in idx_groups:\n                idx_groups[label] = [idx]\n                continue\n            idx_groups[label].append(idx)\n\n        return idx_groups\n        \n    def _make_triplet(self, anchor_image_idx):\n        \"\"\"\n        Return a triplet of an anchor image, a positive image, and a negative image, \n        such that:\n        - A triplet is uniquely identified by its anchor image.\n        - The anchor and positive image aren't the same one.\n        - The positve and negative image indices are randomly chosen on every call.\n        \"\"\"\n        positive_label = int(self._labels[anchor_image_idx].squeeze())\n        positive_group = self._idx_groups[positive_label]\n        negative_group = self._choose_negative_group(positive_label)\n        positive_image_idx = self._choose_positive_image_idx(\n            positive_group, anchor_image_idx\n        )\n        negative_image_idx = random.choice(negative_group)\n        \n        anchor_image_path = self._images[anchor_image_idx]\n        positive_image_path = self._images[positive_image_idx]\n        negative_image_path = self._images[negative_image_idx]\n        \n        anchor_image = np.asarray(PIL.Image.open(anchor_image_path))/255.\n        positive_image = np.asarray(PIL.Image.open(positive_image_path))/255.\n        negative_image = np.asarray(PIL.Image.open(negative_image_path))/255.\n        \n        return np.stack([anchor_image, positive_image, negative_image])\n                \n    def _choose_negative_group(self, positive_label):\n        \"\"\"Choose a group for negative image to be sampled from.\"\"\"\n        possible_negative_labels = [\n            label for label in self._unique_labels if label != positive_label\n        ] \n        negative_label = random.choice(possible_negative_labels)\n        return self._idx_groups[negative_label]\n    \n    def _choose_positive_image_idx(self, positive_group, anchor_image_idx):\n        \"\"\"\n        Choose an index other than the anchor image index from the positive group.\n        \"\"\"\n        possible_positive_image_indices = [\n            idx for idx in positive_group if idx != anchor_image_idx\n        ]\n        positive_image_idx = random.choice(possible_positive_image_indices)\n        return positive_image_idx","metadata":{"id":"wdXtgmxzNJdx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_triplets = ImageTriplets(train_images, train_labels, BATCH_SIZE)\nval_triplets = ImageTriplets(val_images, val_labels, BATCH_SIZE)\n# test_triplets = ImageTriplets(test_images, test_labels, BATCH_SIZE)","metadata":{"id":"phppHthqqemO","outputId":"cdfd799b-596a-4a94-f866-ce3bb5b65dad","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del  train_images\ndel  val_images\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### III - Visualize the some data samples","metadata":{"id":"rxYBGuJy6mys"}},{"cell_type":"code","source":"def show_images_in_triplets(image_triplets):\n    \"\"\"\n    Show images from one triplet on a row and different triplets on different\n    rows.\n    \"\"\"\n    triplet_count = len(image_triplets)\n    fig, axes = plt.subplots(\n        nrows=triplet_count, ncols=3, figsize=(15, 5 * triplet_count)\n    )\n\n    for row, image_triplet, in zip(axes, image_triplets):\n        for grid, image, title in zip(\n            row, image_triplet, [\"anchor\", \"positive\", \"negative\"]\n        ):\n            grid.imshow(image)\n            grid.set_title(title)","metadata":{"id":"5zrWVtussB3S","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random_triplets = train_triplets[random.randrange(len(train_triplets))]\n\n# show_images_in_triplets(random_triplets)","metadata":{"id":"GJgV3yK4rEQS","outputId":"7e4429e3-5511-4341-8bff-6816e02f8380","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## C - Define and train the model","metadata":{}},{"cell_type":"markdown","source":"### I - Define the backbone model","metadata":{}},{"cell_type":"markdown","source":"#### 1. Define the model building blocks","metadata":{}},{"cell_type":"code","source":"def cb_block(input_shape, filters, kernel_size, strides):\n    layers = [\n        keras.layers.Input(input_shape),\n        keras.layers.Conv2D(filters, kernel_size, strides, padding=\"same\"),\n        keras.layers.BatchNormalization(),\n    ]\n    return keras.Sequential(layers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cba_block(input_shape, filters, kernel_size, strides):\n    layers = [\n        keras.layers.Input(input_shape),\n        cb_block(input_shape, filters, kernel_size, strides),\n        keras.layers.ReLU(),\n    ]\n    return keras.Sequential(layers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shallow_feedforward_block(input_shape, filters, strides):\n    input_width, input_height, _ = input_shape\n    layers = [\n        cb_block(input_shape, filters, kernel_size=3, strides=strides),\n        cba_block(\n            (input_width // strides, input_height // strides, filters), \n            filters, \n            kernel_size=3, \n            strides=1,\n        ),\n    ]\n    return keras.Sequential(layers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deep_feedforward_block(input_shape, filters, strides):\n    input_width, input_height, _ = input_shape\n    layers = [\n        cb_block(input_shape, filters // 4, kernel_size=1, strides=strides),\n        cb_block(\n            (input_width // strides, input_height // strides, filters // 4), \n            filters // 4, \n            kernel_size=3, \n            strides=1,\n        ),\n        cba_block(\n            (input_width // strides, input_height // strides, filters // 4), \n            filters, \n            kernel_size=3, \n            strides=1,\n        ),\n    ]\n    return keras.Sequential(layers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dimesion_altering_residual_block(\n    input_shape, filters, strides, feedforward_block\n):\n    inputs = keras.layers.Input(input_shape)\n    feature_maps = (\n        feedforward_block(input_shape, filters, strides)(inputs) \n        + cb_block(input_shape, filters, kernel_size=1, strides=strides)(inputs)\n    )\n    outputs = keras.layers.ReLU()(feature_maps)\n    return keras.Model(inputs, outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def constant_dimension_residual_block(\n    input_shape, feedforward_block\n):\n    *_, filters = input_shape\n    inputs = keras.layers.Input(input_shape)\n    feature_maps = feedforward_block(input_shape, filters, strides=1)(inputs) + inputs\n    outputs = keras.layers.ReLU()(feature_maps)\n    return keras.Model(inputs, outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def repeating_residual_blocks(\n    input_shape, filters, strides, repetitions, feedforward_block,\n):\n    input_width, input_height, _ = input_shape\n    layers = [\n        dimesion_altering_residual_block(\n            input_shape, filters, strides, feedforward_block\n        )\n    ]\n    \n    for _ in range(repetitions - 1):\n        layers.append(\n            constant_dimension_residual_block(\n                (input_width // strides, input_height // strides, filters),\n                feedforward_block=feedforward_block,\n            )\n        )\n        \n    return keras.Sequential(layers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Define a general ResNet architecture","metadata":{}},{"cell_type":"code","source":"def resnet(\n    input_shape, \n    output_shape, \n    first_block_filters,\n    repetitions_by_blocks,\n    feedforward_block,\n    name=\"ResNet\",\n):\n    input_width, input_height, _ = input_shape\n        \n    layers = [\n        # conv1\n        keras.Input(input_shape),\n        cba_block(input_shape, filters=64, kernel_size=3, strides=2),\n        # conv2_x\n        keras.layers.MaxPooling2D(pool_size=3, strides=2, padding=\"same\"),\n        repeating_residual_blocks(\n            (input_width // 4, input_height // 4, 64), \n            first_block_filters, \n            strides=1, \n            repetitions=repetitions_by_blocks[0],\n            feedforward_block=feedforward_block,\n        ),\n    ]\n        \n    # conv3_x -> conv5_x\n    for idx, repetitions in enumerate(repetitions_by_blocks[1:]):\n        layers.append(\n            repeating_residual_blocks(\n                (\n                    input_width // 2 ** (idx + 2),\n                    input_height // 2 ** (idx + 2),\n                    first_block_filters * 2 ** idx,\n                ), \n                first_block_filters * 2 ** (idx + 1), \n                strides=2, \n                repetitions=repetitions,\n                feedforward_block=feedforward_block,\n            )\n        )\n    \n    # average_pooling & fc\n    layers.extend(\n        [\n            keras.layers.AveragePooling2D(padding=\"same\"),\n            keras.layers.Flatten(),\n            keras.layers.Dense(units=output_shape),\n        ]\n    )\n    \n    return keras.Sequential(layers, name=name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Define different versions of ResNet","metadata":{}},{"cell_type":"code","source":"def resnet18(input_shape, output_shape, name=\"ResNet-18\"):\n    return resnet(\n        input_shape,\n        output_shape,\n        first_block_filters=64,\n        repetitions_by_blocks=[2, 2, 2, 2],\n        feedforward_block=shallow_feedforward_block,\n        name=name,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resnet34(input_shape, output_shape, name=\"ResNet-34\"):\n    return resnet(\n        input_shape,\n        output_shape,\n        first_block_filters=64,\n        repetitions_by_blocks=[3, 4, 6, 3],\n        feedforward_block=shallow_feedforward_block,\n        name=name,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resnet50(input_shape, output_shape, name=\"ResNet-50\"):\n    return resnet(\n        input_shape,\n        output_shape,\n        first_block_filters=256,\n        repetitions_by_blocks=[3, 4, 6, 3],\n        feedforward_block=deep_feedforward_block,\n        name=name,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resnet101(input_shape, output_shape, name=\"ResNet-101\"):\n    return resnet(\n        input_shape,\n        output_shape,\n        first_block_filters=256,\n        repetitions_by_blocks=[3, 4, 23, 3],\n        feedforward_block=deep_feedforward_block,\n        name=name,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resnet152(input_shape, output_shape, name=\"ResNet-152\"):\n    return resnet(\n        input_shape,\n        output_shape,\n        first_block_filters=256,\n        repetitions_by_blocks=[3, 8, 36, 3],\n        feedforward_block=deep_feedforward_block,\n        name=name,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### II - Define the FaceNet model","metadata":{}},{"cell_type":"markdown","source":"#### 1. Define augmentation layer","metadata":{}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n  keras.layers.RandomRotation(0.8),\n#   keras.layers.RandomCrop(IMAGE_SIZE_H, IMAGE_SIZE_W),\n])\n\n\"\"\"resize image for valid input\"\"\"\nimage_resize = tf.keras.Sequential([\n  keras.layers.Resizing(IMAGE_SIZE_H, IMAGE_SIZE_W)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Define the FaceNet model","metadata":{}},{"cell_type":"code","source":"class FaceNet(keras.Model):\n    def __init__(self, backbone, loss_margin=0.5, **kwargs):\n        super().__init__(**kwargs)\n        self._backbone = backbone\n        self._loss_margin = loss_margin\n        self.loss_tracker = tf.keras.metrics.Accuracy(name='accuracy')\n        \n    def call(self, image):\n        return self._backbone(image_resize(image))\n\n    def triplet_embeddings(self, images, training = False):\n        anchor_images = images[:, 0]\n        positive_images = images[:, 1]\n        negative_images = images[:, 2]\n        \n        if training:\n            anchor_images = data_augmentation(anchor_images)\n            positive_images = data_augmentation(positive_images)\n            negative_images = data_augmentation(negative_images)\n            \n    \n        anchor_embeddings = self(anchor_images, training = training)\n        positive_embeddings = self(positive_images, training = training)\n        negative_embeddings = self(negative_images, training = training)\n    \n        embeddings = tf.stack(\n            [anchor_embeddings, positive_embeddings, negative_embeddings], axis=1\n        )\n        return embeddings\n    \n    def train_step(self, images):\n        with tf.GradientTape() as tape:\n            embeddings = self.triplet_embeddings(images, training=True)\n            \n            loss = self.compute_loss(embeddings)\n            \n        gradients = tape.gradient(loss, self.trainable_variables)\n        self.optimizer.apply_gradients(\n            zip(gradients, self.trainable_variables)\n        )\n        return {\"loss\": loss, \"accuracy\": self.loss_tracker.result()}\n    \n    def test_step(self, images):\n        embeddings = self.triplet_embeddings(images, training=False)    \n        loss = self.compute_loss(embeddings)\n        return {\"loss\": loss, \"accuracy\": self.loss_tracker.result()}\n    \n    def compute_loss(self, embeddings):\n        anchor_embeddings = embeddings[:, 0]\n        positive_embeddings = embeddings[:, 1]\n        negative_embeddings = embeddings[:, 2]\n\n        ap_distance = tf.math.reduce_euclidean_norm(\n            anchor_embeddings - positive_embeddings, axis=1\n        )\n\n        an_distance = tf.math.reduce_euclidean_norm(\n            anchor_embeddings - negative_embeddings, axis=1\n        )\n\n#         loss = tf.reduce_max(\n#             ap_distance - an_distance + self._loss_margin, 0\n#         )\n        loss = tf.math.maximum(ap_distance - an_distance + self._loss_margin, 0)\n        self.loss_tracker.update_state(tf.math.maximum(ap_distance - an_distance, 0), np.zeros(BATCH_SIZE))\n        loss = tf.reduce_sum(loss)\n        return loss    \n    \n    def get_config(self):\n        base_config = super().get_config()\n        return {\n            **base_config,\n            \"backbone\": self._backbone,\n            \"loss_margin\": self._loss_margin,\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"backbone = resnet18(input_shape=(IMAGE_SIZE_H, IMAGE_SIZE_W, 3), output_shape=130)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FaceNet(backbone=backbone)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = np.stack([train_triplets[0][0][0]])\nprint(\"test shape\", test.shape)\nmodel(test).shape","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=keras.optimizers.Adam())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(patience=14, restore_best_weights=True, mode='max', monitor='val_accuracy'),\n    keras.callbacks.ReduceLROnPlateau(patience=3),\n    keras.callbacks.ModelCheckpoint(CHECKPOINT_PATH, save_best_only=True, monitor=\"val_accuracy\", mode='max'),\n    keras.callbacks.TensorBoard(),\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    train_triplets, \n    validation_data=val_triplets, \n    epochs=EPOCHS, \n    callbacks=callbacks,\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('model', include_optimizer=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = keras.models.load_model('checkpoint')\ntest = np.stack([train_triplets[0][0][0]])\nprint(test.shape)\npred = m.predict(test)\nprint(pred.shape)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('output_kaggle', 'zip', '/kaggle/working/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %load_ext tensorboard\n# %tensorboard --logdir \"logs\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}